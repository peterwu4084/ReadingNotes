# Ray Coreå¯¼è§ˆ: è¿œç¨‹ä»»åŠ¡

## ä»‹ç»

Rayå…è®¸ä»»æ„Pythonå‡½æ•°åœ¨å•ç‹¬çš„Pythonå·¥ä½œçº¿ç¨‹ä¸Šå¼‚æ­¥æ‰§è¡Œã€‚è¿™äº›å¼‚æ­¥Rayå‡½æ•°ç§°ä¸ºâ€œTaskâ€ã€‚å¯ä»¥é€šè¿‡cpuã€gpuå’Œè‡ªå®šä¹‰èµ„æºæ¥æŒ‡å®šä»»åŠ¡çš„èµ„æºéœ€æ±‚ã€‚é›†ç¾¤è°ƒåº¦å™¨ä½¿ç”¨è¿™äº›èµ„æºè¯·æ±‚åœ¨é›†ç¾¤ä¸­åˆ†å‘ä»»åŠ¡ï¼Œä»¥ä¾¿å¹¶è¡Œæ‰§è¡Œã€‚

![ray_tasks_actors_immutable_objects](./assets/ray_tasks_actors_immutable_objects.png)

![ray_tasks](./assets/ray_tasks.png)

## å­¦ä¹ ç›®æ ‡

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½ å°†å­¦ä¹ :

- è¿œç¨‹ä»»åŠ¡å¹¶è¡Œæ¨¡å¼

- ä½œä¸ºåˆ†å¸ƒå¼ä»»åŠ¡çš„æ— çŠ¶æ€è¿œç¨‹å‡½æ•°

- ä¸²è¡Œä¸å¹¶è¡Œæ‰§è¡Œ

- ç†è§£Ray taskçš„æ¦‚å¿µ

- ç®€å•çš„APIå°†ç°æœ‰çš„Pythonå‡½æ•°è½¬æ¢ä¸ºRayè¿œç¨‹ä»»åŠ¡

- é€šè¿‡ç¤ºä¾‹åˆ†åˆ«æ¯”è¾ƒä¸²è¡Œä¸åˆ†å¸ƒå¼Pythonå‡½æ•°å’ŒRayä»»åŠ¡

## ä»»åŠ¡å¹¶è¡Œæ¨¡å¼

Rayé€šè¿‡ `@ray.remote` ä¿®é¥°å‡½æ•°ï¼Œä½¿å…¶æˆä¸ºæ— çŠ¶æ€ä»»åŠ¡ï¼Œåœ¨é›†ç¾¤ä¸­çš„RayèŠ‚ç‚¹çš„å·¥ä½œå™¨ä¸Šè°ƒåº¦ã€‚

å®ƒä»¬å°†åœ¨é›†ç¾¤ä¸Šçš„ä½•å¤„æ‰§è¡Œ(ä»¥åŠåœ¨å“ªä¸ªèŠ‚ç‚¹ä¸Šç”±å“ªä¸ªå·¥ä½œè¿›ç¨‹æ‰§è¡Œ)ï¼Œæ‚¨ä¸å¿…æ‹…å¿ƒå…¶ç»†èŠ‚ã€‚ä¸€åˆ‡éƒ½å·²å®‰æ’å¥½äº†ï¼Œæ‰€æœ‰çš„å·¥ä½œéƒ½ç”±Rayå®Œæˆã€‚æ‚¨åªéœ€å°†ç°æœ‰çš„Pythonå‡½æ•°è½¬æ¢ä¸ºåˆ†å¸ƒå¼æ— çŠ¶æ€Rayä»»åŠ¡ï¼šå°±è¿™ä¹ˆç®€å•!

### ä¸²è¡Œä¸å¹¶è¡Œæ‰§è¡Œ

ä½œä¸ºå¸¸è§„Pythonå‡½æ•°çš„ä¸²è¡Œä»»åŠ¡ä»¥é¡ºåºçš„æ–¹å¼æ‰§è¡Œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å¦‚æœæˆ‘å¯åŠ¨åä¸ªä»»åŠ¡ï¼Œå®ƒä»¬å°†ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°åœ¨å•ä¸ªworkerä¸Šè¿è¡Œã€‚

![timeline_of_sequential_tasks](./assets/timeline_of_sequential_tasks.png)

ä¸ä¸²è¡Œæ‰§è¡Œç›¸æ¯”ï¼ŒRayä»»åŠ¡æ˜¯å¹¶è¡Œæ‰§è¡Œçš„ï¼Œè°ƒåº¦åœ¨ä¸åŒçš„å·¥ä½œå™¨ä¸Šã€‚Rayletå°†æ ¹æ®è°ƒåº¦ç­–ç•¥è°ƒåº¦è¿™äº›ä»»åŠ¡ã€‚

![sample_timeline_of_parallel_tasks](./assets/sample_timeline_of_parallel_tasks.png)

è®©æˆ‘ä»¬å¯¹æ¯”ä¸€äº›ä»»åŠ¡çš„ä¸²è¡Œè¿è¡Œå’Œå¹¶è¡Œè¿è¡Œã€‚ä¸ºäº†è¯´æ˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»»åŠ¡:

- ç”Ÿæˆæ–æ³¢é‚£å¥‘æ•°åˆ—

- ç”¨è’™ç‰¹å¡ç½—æ–¹æ³•è®¡ç®— $\pi$

- è½¬æ¢å’Œå¤„ç†å¤§å‹é«˜åˆ†è¾¨ç‡å›¾åƒ

- ä½¿ç”¨Ray Taskè¿›è¡Œæ‰¹æ¨ç†

ä½†é¦–å…ˆï¼Œè®©æˆ‘ä»¬äº†è§£ä¸€äº›åŸºæœ¬æ¦‚å¿µ: åŸå§‹Pythonå‡½æ•°å’Œä¿®é¥°åçš„å‡½æ•°ä¹‹é—´å­˜åœ¨ä¸€äº›å…³é”®åŒºåˆ«:

- è°ƒç”¨: ä½¿ç”¨ `func_name()` è°ƒç”¨å¸¸è§„ç‰ˆæœ¬ï¼Œè€Œä½¿ç”¨ `func_name.remote()` è°ƒç”¨è¿œç¨‹Rayç‰ˆæœ¬ã€‚æ‰€æœ‰Rayè¿œç¨‹æ‰§è¡Œæ–¹æ³•éƒ½æ˜¯è¿™ä¸ªæ¨¡å¼ã€‚

- æ‰§è¡Œæ–¹å¼å’Œè¿”å›å€¼: Python å¸¸è§„ç‰ˆæœ¬çš„å‡½æ•°åŒæ­¥æ‰§è¡Œå¹¶è¿”å›ç»“æœï¼Œè€ŒRayä»»åŠ¡ `func_name.remote()` ç«‹å³è¿”å› `ObjectRef`ï¼Œç„¶ååœ¨è¿œç¨‹å·¥ä½œè¿›ç¨‹çš„åå°æ‰§è¡Œä»»åŠ¡ã€‚é€šè¿‡åœ¨ `ObjectRef` ä¸Šè°ƒç”¨ `ray.get(ObjectRef)` æ¥è·å¾—ç»“æœï¼Œè¿™æ˜¯ä¸€ä¸ªé˜»å¡å‡½æ•°ã€‚

è®©æˆ‘ä»¬åœ¨æœ¬åœ°æœºå™¨ä¸Šå¯åŠ¨ä¸€ä¸ªRayé›†ç¾¤ã€‚

``` python
import os
import time
import logging
import math
import random

from pathlib import Path
from typing import Tuple, List

import numpy as np
import pandas as pd
import pyarrow.parquet as pq
import tqdm
import ray

if ray.is_initialized:
    ray.shutdown()
ray.init(logging_level=logging.ERROR)
```

## ä¾‹1: ç”Ÿæˆæ–æ³¢é‚£å¥‘æ•°åˆ—

è®©æˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªå‡½æ•°:ä¸€ä¸ªä¸²è¡Œè¿è¡Œï¼Œå¦ä¸€ä¸ªåœ¨Rayé›†ç¾¤(æœ¬åœ°æˆ–è¿œç¨‹)ä¸Šè¿è¡Œã€‚è¿™ä¸ªä¾‹å­æ˜¯ä»æˆ‘ä»¬çš„åšå®¢ä¸­å€Ÿç”¨å’Œé‡æ„çš„:[ç”¨Rayç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªåˆ†å¸ƒå¼Pythonåº”ç”¨ç¨‹åº](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray)ã€‚(è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ•™ç¨‹ï¼Œä»ä¸ºä»€ä¹ˆå’Œä½•æ—¶ä½¿ç”¨Ray taskså’Œactorsçš„æ¦‚å¿µå¼€å§‹ã€‚å¼ºçƒˆæ¨èé˜…è¯»!)

``` python
SEQUENCE_SIZE = 100000

# æœ¬åœ°æ‰§è¡Œçš„å‡½æ•°
def generate_fibonacci(sequence_size):
    fibonacci = []
    for i in range(0, sequence_size):
        if i < 2:
            fibonacci.append(i)
            continue
        fibonacci.append(fibonacci[i - 1] + fibonacci[i - 2])
    return len(fibonacci)

# ç”¨äºè¿œç¨‹Ray taskçš„å‡½æ•°
@ray.remote
def generate_fibonacci_distributed(sequence_size):
    return generate_fibonacci(sequence_size)

# è·å–å†…æ ¸çš„æ•°é‡
print(os.cpu_count()) # 16

# å•ä¸ªè¿›ç¨‹ä¸­çš„æ™®é€šPython
def run_local(sequence_size):
    results = [generate_fibonacci(sequence_size) for _ in range(os.cpu_count())]

# åˆ†å¸ƒåœ¨Rayé›†ç¾¤ä¸Š
def run_remote(sequence_size):
    results = ray.get([generate_fibonacci_distributed.remote(sequence_size) for _ in range(os.cpu_count())])
    return results

start = time.time()
run_local(SEQUENCE_SIZE)
end = time.time()

print(f"Local: {end - start}") # 4.63s

start = time.time()
run_remote(SEQUENCE_SIZE)
end = time.time()
print(f"Remote: {end - start}") # 2.55s
```

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œä½œä¸ºRay Tasksè¿è¡Œæ—¶ï¼Œæˆ‘ä»¬åªéœ€æ·»åŠ ä¸€ä¸ªPythonè£…é¥°å™¨  `Ray .remote` å°±å¯ä»¥æ˜¾è‘—æå‡æ€§èƒ½ğŸ“ˆã€‚

## ä¾‹2: ç”¨è’™ç‰¹å¡ç½—æ–¹æ³•è®¡ç®— $\pi$

è®©æˆ‘ä»¬ç”¨è’™ç‰¹å¡ç½—æ–¹æ³•ä¼°è®¡ $\pi$ çš„å€¼ã€‚æˆ‘ä»¬éšæœºæŠ½å–2x2å¹³æ–¹å†…çš„ç‚¹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥åŸç‚¹ä¸ºä¸­å¿ƒçš„å•ä½åœ†å†…åŒ…å«çš„ç‚¹çš„æ¯”ä¾‹æ¥ä¼°è®¡åœ†çš„é¢ç§¯ä¸æ­£æ–¹å½¢çš„é¢ç§¯ä¹‹æ¯”ã€‚

å‡è®¾æˆ‘ä»¬çŸ¥é“çœŸå®çš„æ¯”ç‡æ˜¯Ï€/4ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¼°ç®—çš„æ¯”ç‡ä¹˜ä»¥4æ¥è¿‘ä¼¼ $\pi$ çš„å€¼ã€‚æˆ‘ä»¬åœ¨è®¡ç®—è¿™ä¸ªè¿‘ä¼¼å€¼æ—¶é‡‡æ ·çš„ç‚¹è¶Šå¤šï¼Œæˆ‘ä»¬å°±è¶Šæ¥è¿‘ $\pi$ çš„çœŸå®å€¼å’Œæ‰€éœ€çš„å°æ•°ç‚¹ã€‚

å®šä¹‰ä¸€ä¸ªé€šå¸¸çš„å‡½æ•°æ¥è®¡ç®—åœ†ä¸­çš„æ ·æœ¬æ•°ã€‚è¿™æ˜¯é€šè¿‡åœ¨ $(-1,1)$çš„ç»Ÿä¸€å€¼ä¹‹é—´éšæœºæŠ½æ · `num_samples` ä¸ª $x, y$ çš„æ¥å®Œæˆçš„ã€‚ä½¿ç”¨ `math.hypot`` å‡½æ•°ï¼Œæˆ‘ä»¬è®¡ç®—dç‚¹æ˜¯å¦è½åœ¨åœ†å†…ã€‚

``` python
NUM_SAMPLING_TASKS = os.cpu_count()
NUM_SAMPLES_PER_TASK = 10_000_000
TOTAL_NUM_SAMPLES = NUM_SAMPLING_TASKS * NUM_SAMPLES_PER_TASK

def sampling_task(num_samples: int, task_id: int, verbose=True) -> int:
    num_inside = 0
    for i in range(num_samples):
        x, y = random.uniform(-1, 1), random.uniform(-1, 1)
        if math.hypot(x, y) <= 1:
            num_inside += 1
    if verbose:
        print(f"Task id: {task_id} | Samples in the circle: {num_inside}")
    return num_inside
```

å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œé€šè¿‡åœ¨ä¸€ä¸ªæ¨å¯¼å¼åˆ—è¡¨ä¸­å¯åŠ¨ `NUM_SAMPLING_TASKS` ä¸²è¡Œä»»åŠ¡æ¥ä¸²è¡Œåœ°è¿è¡Œè¿™ä¸ªä»»åŠ¡ã€‚

``` python
def run_serial(sample_size) -> List[int]:
    results = [sampling_task(sample_size, i) for i in range(NUM_SAMPLING_TASKS)]
    return results
```

é€šè¿‡è¿œç¨‹Rayä»»åŠ¡æ¥è¿è¡Œï¼Œå®ƒè°ƒç”¨æˆ‘ä»¬çš„é‡‡æ ·å‡½æ•°ï¼Œä½†æ˜¯å› ä¸ºå®ƒæ˜¯ç”¨@rayè£…é¥°çš„ã€‚è¿œç¨‹æ—¶ï¼Œä»»åŠ¡å°†åœ¨Rayé›†ç¾¤ä¸Šç»‘å®šåˆ°ä¸€ä¸ªæ ¸å¿ƒçš„å·¥ä½œè¿›ç¨‹ä¸Šè¿è¡Œã€‚

``` python
@ray.remote
def sample_task_distributed(sample_size, i) -> object:
    return sampling_task(sample_size, i)

def run_distributed(sample_size) -> List[int]:
    # åœ¨ä¸€ä¸ªæ¨å¯¼å¼åˆ—è¡¨ä¸­å¯åŠ¨Rayè¿œç¨‹ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ç«‹å³è¿”å›ä¸€ä¸ªæœªæ¥çš„ObjectRef
    # ä½¿ç”¨ray.getè·å–è®¡ç®—å€¼ï¼›è¿™å°†é˜»å¡ç›´åˆ°ObjectRefè¢«è§£ææˆ–å®ƒçš„å€¼è¢«å…·ä½“åŒ–ã€‚
    results = ray.get([sample_task_distributed.remote(sample_size, i) for i in range(NUM_SAMPLING_TASKS)])
    return results
```

å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œé€šè¿‡ä»é‡‡æ ·ä»»åŠ¡ä¸­è·å–åœ†å†…çš„æ‰€æœ‰æ ·æœ¬æ•°æ¥ä¼°è®¡ $\pi$ çš„å€¼ã€‚

``` python
def calculate_pi(results: List[int]) -> float:
    return 4 * sum(results) / TOTAL_NUM_SAMPLES

# ä¸²è¡Œè®¡ç®—Ï€
start = time.time()
results = run_serial(NUM_SAMPLES_PER_TASK)
pi = calculate_pi(results)
end = time.time()
print(f"Estimated value of pi is: {pi:5f}")
print(f"Serial execution time: {end - start:5f}") # 76.42

# åˆ†å¸ƒå¼è®¡ç®—Ï€
start = time.time()
results = run_distributed(NUM_SAMPLES_PER_TASK)
pi = calculate_pi(results)
end = time.time()
print(f"Estimated value of pi is: {pi:5f}")
print(f"Distributed execution time: {end - start:5f}") # 13.73
```

åœ¨Rayä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°é€Ÿåº¦åŠ å¿«äº†~6Xã€‚

## ä¾‹3: å¦‚ä½•ä½¿ç”¨Rayåˆ†å¸ƒå¼ä»»åŠ¡è¿›è¡Œå›¾åƒå˜æ¢å’Œè®¡ç®—

å¯¹äºæœ¬ä¾‹ï¼Œæˆ‘ä»¬å°†é€šè¿‡å˜æ¢å’Œè®¡ç®—å¤§å‹é«˜åˆ†è¾¨ç‡å›¾åƒæ¥æ¨¡æ‹Ÿè®¡ç®—å¯†é›†å‹ä»»åŠ¡ã€‚è¿™äº›ä»»åŠ¡åœ¨è®­ç»ƒDNNå›¾åƒåˆ†ç±»ä¸­å¹¶ä¸å°‘è§ã€‚

PyTorch `torchvisionã€‚transforms` APIæä¾›äº†è®¸å¤šå˜æ¢APIã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨å‡ ä¸ªï¼Œä»¥åŠä¸€äº›numpyå’Œtorch.tensorçš„æ“ä½œã€‚æˆ‘ä»¬çš„ä»»åŠ¡å°†æ‰§è¡Œä»¥ä¸‹è®¡ç®—å¯†é›†å‹å˜æ¢ï¼š

1. ä½¿ç”¨PIL apiæ¥æ¨¡ç³Šå›¾åƒï¼›

2. ä½¿ç”¨pytorchçš„ `TrivalAugmentWide`ï¼›

3. å°†å›¾åƒè½¬æ¢ä¸ºnumpy arrayå’Œpytorch tensorï¼Œå¹¶æ‰§è¡Œnumpyå’Œtorchå¼ é‡æ“ä½œï¼Œä¾‹å¦‚è½¬ç½®ã€ä¹˜æ³•ï¼›

4. æŒ‡æ•°å¹‚å’Œä¸å¼ é‡ç›¸ä¹˜ï¼›

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¯”è¾ƒä¸²è¡Œè¿è¡Œè¿™äº›ä»»åŠ¡å’Œä½œä¸ºä¸€ä¸ªRayä»»åŠ¡åˆ†å¸ƒå¼è¿è¡Œè¿™äº›ä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´ã€‚

å®šä¹‰ä¸€äº›å¸¸é‡ï¼Œè¿™äº›å¸¸é‡å¯ä»¥ä½œä¸ºç»ƒä¹ çš„ä¸€éƒ¨åˆ†è¿›è¡Œè°ƒæ•´ï¼Œä»¥è¿›è¡Œä¸åŒæ‰¹å¤§å°çš„å®éªŒã€‚

``` python
import tasks_helper_utils as t_utils

DATA_DIR = Path(os.getcwd() + "/task_images")
BATCHES = [10, 20, 30, 40, 50]
SERIAL_BATCH_TIMES = []
DISTRIBUTED_BATCH_TIMES = []

# å®šä¹‰ä¸€ä¸ªRay taskæ¥è½¬æ¢ï¼Œå¢å¼ºå’Œæ‰§è¡Œä¸€äº›è®¡ç®—å¯†é›†å‹çš„ä»»åŠ¡
@ray.remote
def augment_image_distributed(image_ref: object, fetch_image) -> List[object]:
    return t_utils.transform_image(image_ref, fetch_image)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨å•ä¸ªèŠ‚ç‚¹ã€å•ä¸ªæ ¸å¿ƒä¸Šä¸²è¡Œåœ°è¿è¡Œè¿™äº›è½¬æ¢ä»»åŠ¡
def run_serially(img_list_refs: List) -> List[Tuple[int, float]]:
    transform_results = [t_utils.transform_image(image_ref, fetch_image=True) for image_ref in tqdm.tqdm(img_list_refs)]
    return transform_results

# å®šä¹‰å‡½æ•°ä»¥åˆ†å¸ƒå¼åœ°è¿è¡Œè¿™äº›è½¬æ¢ä»»åŠ¡
def run_distributed(img_list_refs: List[object]) -> List[Tuple[iint, float]]:
    return ray.get([augment_image_distributed.remote(image_ref, False) for img in tqdm.tqdm(img_list_refs)])
```

è®©æˆ‘ä»¬ä¸‹è½½100å¼ å¤§å›¾ç‰‡ï¼Œæ¯å¼ å›¾ç‰‡çš„å¤§å°åœ¨5-20mbä»¥ä¸Šï¼Œåˆ†è¾¨ç‡å¤§äº(4000ã€3500)åƒç´ ã€‚å®ƒåªä¼šä¸‹è½½ä¸€æ¬¡ã€‚

``` python
# æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœæ˜¯ï¼Œå¿½ç•¥ä¸‹è½½ã€‚
if not os.path.exists(DATA_DIR):
    os.mkdir(DATA_DIR)
    print(f"downloading images...")
    for url in tqdm.tqdm(t_utils.URLS):
        t_utils.download_file(url, DATA_DIR)

# è·å–æ•´ä¸ªå›¾åƒåˆ—è¡¨      
image_list = list(DATA_DIR.glob("*.jpg"))
```

ç”±äºæˆ‘ä»¬çš„å›¾åƒå¾ˆå¤§ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒä»¬æ”¾åœ¨Ray Distributedå¯¹è±¡å­˜å‚¨ä¸­ã€‚

``` python
# å°†æ‰€æœ‰å›¾åƒæ”¾å…¥å¯¹è±¡å­˜å‚¨ä¸­ã€‚å› ä¸ºRayä»»åŠ¡å¯èƒ½æ˜¯åˆ†å¸ƒ
# åœ¨ä¸åŒçš„æœºå™¨ä¸Šï¼Œå·¥ä½œçº¿ç¨‹ä¸Šå¯èƒ½æ²¡æœ‰DATA_DIRã€‚ç„¶è€Œ,
# å°†å®ƒä»¬æ”¾å…¥Rayåˆ†å¸ƒå¼å¯¹è±¡å™¨ä¸­ï¼Œå¯ä»¥åœ¨Ray workerä¸Š
# è®¿é—®ä»»ä½•è°ƒåº¦è¿œç¨‹ä»»åŠ¡
image_list_refs = [t_utils.insert_into_object_store(image) for image in image_list]
```

æˆ‘ä»¬å°†ä»¥10ä¸ªæ‰¹æ¬¡(è¿™å¯ä»¥æ›´æ”¹ä¸º20æˆ–25ç­‰)è¿­ä»£å›¾åƒå¹¶å¤„ç†å®ƒä»¬ã€‚ä¸ºäº†æ¨¡æ‹Ÿå›¾åƒä¸Šçš„è®¡ç®—æœºå¯†é›†å‹æ“ä½œï¼Œæˆ‘ä»¬æ­£åœ¨è¿›è¡Œä¸Šé¢æè¿°çš„å¼ é‡å˜æ¢å’Œè®¡ç®—ã€‚

``` python
for idx in BATCHES:
    # ä½¿ç”¨ç´¢å¼•è·å–Nä¸ªæŒ‡å‘å›¾åƒçš„url
    image_batch_list_refs = image_list_refs[:idx]
    print(f"\nRunning {len(image_batch_list_refs)} tasks serially ...")
    
    # ä¸²è¡Œè¿è¡Œ
    start = time.perf_counter()
    serial_results = run_serially(image_batch_list_refs)
    end = time.perf_counter()
    elapsed = end - start
    
    # ä»¥å…ƒç»„çš„å½¢å¼è·Ÿè¸ªæ‰¹å¤„ç†ã€æ‰§è¡Œæ—¶é—´
    SERIAL_BATCH_TIMES.append((idx, round(elapsed, 2)))
    print(f"Serial transformation/computations of {len(image_batch_list_refs)} images: {elapsed:.2f}) sec")
```